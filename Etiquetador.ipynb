{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from facenet_pytorch import MTCNN\n",
    "import torch\n",
    "import numpy as np\n",
    "import mmcv, cv2\n",
    "from PIL import Image, ImageDraw\n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Running on device: {}'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcnn = MTCNN(keep_all=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = mmcv.VideoReader('self1.mp4')##Nombre del archivo o el directorio completo en caso de estar fuera de la carpeta del proyecto\n",
    "frames = [Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)) for frame in video]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x=len(frames)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nivel_atencion=[]\n",
    "emocion=[]\n",
    "box=[]\n",
    "land_mark=[]\n",
    "for i in range(0,x,30):\n",
    "    \n",
    "    print(i)\n",
    "    display.display(frames[i])\n",
    "\n",
    "    etiqueta1=input(\"Ingrese un numero del 1 al 10 para calificar la atencion\")\n",
    "    etiqueta2=input(\"Ingrese un numero del 1 al 7 para identificar la emocion\")\n",
    "    \n",
    "    z=x-i\n",
    "    if (z>= 30):\n",
    "        alfa=30+i\n",
    "    else:\n",
    "        alfa=z+i\n",
    "\n",
    "    for j in range (i,alfa):\n",
    "        nivel_atencion.append(etiqueta1)\n",
    "        emocion.append(etiqueta2)\n",
    "        boxes, _, land_marks = mtcnn.detect(frames[i], landmarks=True)\n",
    "        box.append(boxes)\n",
    "        land_mark.append(land_marks)\n",
    "        frames[j]= 0\n",
    "\n",
    "    display.clear_output()\n",
    "frames=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "labels={'atencion':nivel_atencion,'emocion':emocion}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df=pd.DataFrame.from_dict(labels,orient=\"index\",dtype='int')\n",
    "df.to_csv('file_name.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "data_dict=df.to_dict('index')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitad2cb1cacda64ced910abd25a6bd7983",
   "display_name": "Python 3.7.6 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}